setwd("C:/Users/disaini/Desktop/CourseraWD")
getwd()
list.files()
if(!file.exists("data")) {
    dir.create("data")
}
list.files()
# download Baltimore camera data 
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile="./data/cameras.csv") # ADD (, method="curl") for linux/mac
list.files("./data") # "cameras.csv" 
dateDownloaded <- date()
dateDownloaded
#read.table() - This is the main function for reading data into R
##Flexible and robust but requires more parameters
##Reads the data into RAM - big data can cause problems
##Important parameters file, header, sep, row.names, nrows
##Related: read.csv(), read.csv2()
cameraData <- read.table("./data/cameras.csv")
#Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
#line 1 did not have 13 elements (coz read.table() looks for a tab delimited file)
head(cameraData)
#Error in head(cameraData) : object 'cameraData' not found coz R could not read the file
##hence use parameter sep="," to convey that look for a comma delimited file
## and also header=TRUE to convey that variable name is included at the top of each column
cameraData <- read.table("./data/cameras.csv", sep=",", header=TRUE)
head(cameraData) # fetches top 6 rows of the file
# same thing can be done using read.csv() function
cameraData <- read.csv("./data/cameras.csv") # read.csv automatically sets sep="," and header=TRUE
head(cameraData)
## Other imp parameters that can be passed to read.table()
#quote - you can tell R whether there are any quoted values quote="" means no quotes.
#na.strings - set the character that represents a missing value.
#nrows - how many rows to read of the file (e.g. nrows=10 reads 10 lines).
#skip - number of lines to skip before starting to read
##TIP: The biggest trouble with reading flat files are quotation marks ` or " placed in data values, setting quote="" often resolves these.
# Reading excel files
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/cameras.xlsx")
dateDownloaded <- date()
dateDownloaded
list.files("./data") #"cameras.csv"  "cameras.xlsx"
# read.xlsx(), read.xlsx2() {xlsx package}
library(xlsx) # loads the xlsx package
#Error in library(xlsx) : there is no package called ‘xlsx’ since package is not installed, so install it first
install.packages('xlsx') #  or install.packages('xlsx',repos='http://cran.r-project.org')
library(xlsx) # now load the package again
# read.xslx() - to read excel files, sheetIndex conveys which sheet to read data from, header=TRUE conveys columns are labelled
cameraData <- read.xlsx("./data/cameras.xlsx",sheetIndex=1,header=TRUE)
#Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  : 
#java.util.zip.ZipException: invalid entry size (expected 500 but got 502 bytes)
# To solve this issue, use mode="wb" while downloading the excel file
download.file(fileUrl,destfile="./data/cameras.xlsx", mode="wb") # download data again
cameraData <- read.xlsx("./data/cameras.xlsx",sheetIndex=1,header=TRUE) # try reading data again -> success :)
head(cameraData) # fetches first 6 rows of data, looks same as that of csv data
# To read specfic rows and columns do as follows:
colIndex <- 2:3 # to read columns 2 and 3
rowIndex <- 1:4 # to read rows 1 to 4 (here row 1 is column labels)
cameraDataSubset <- read.xlsx("./data/cameras.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
cameraDataSubset
#The write.xlsx function will write out an Excel file with similar arguments.
#read.xlsx2 is much faster than read.xlsx but for reading subsets of rows may be slightly unstable.
#The XLConnect package has more options for writing and manipulating Excel files
#The XLConnect vignette ("http://cran.r-project.org/web/packages/XLConnect/vignettes/XLConnect.pdf") is a good place to start for that package
#In general it is advised to store your data in either a database or in comma separated files (.csv) or tab separated files (.tab/.txt) as they are easier to distribute.
## Reading XML
#XML:Extensible markup language -> widely used to store structured data
#Two components : Markup (labels that give the text structure) and Content (the actual text of the document inbetween the labels)
install.packages('XML') # install the XML package
library(XML) # load the XML package
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE) # loads the file into internal memory of R in a way that you can parse it and get access to different parts of it
doc
rootNode <- xmlRoot(doc) # gives access to root node of the xml i.e. wrapper element for the entire doc
rootNode # loads the whole root node
xmlName(rootNode) # "breakfast_menu" : to get the name of the root node 
names(rootNode) # tells all the nested elements within that rootNode only till next level not till innermost node
##Directly access parts of the XML document
rootNode[[1]] # to fetch first node of root node
rootNode[[1]][[3]] # fetches third node of first node
##Programatically extract parts of the file
xmlSApply(rootNode, xmlValue) # loops through the XML object "rootNode" and "xmlValue" extracts value from all its nodes
# XPath:  http://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf
xpathSApply(rootNode, "//name", xmlValue) # fetches values for all the nodes with tag "name"
xpathSApply(rootNode, "//price", xmlValue) # fetches values for all the nodes with tag "price"
xpathSApply(rootNode, "//description", xmlValue)
xpathSApply(rootNode, "//calories", xmlValue)
## Reading 
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileUrl, useInternal=TRUE) # function to parse an HTML file
scores <- xpathSApply(doc, "//li[@class='score']", xmlValue)
teams <- xpathSApply(doc, "//li[@class='team-name']", xmlValue)
scores # page doesn't have this class anymore
teams # page doesn't have this class anymore
#Short guide on XML package : http://www.omegahat.org/RSXML/shortIntro.pdf
#Long guide on XML package : http://www.omegahat.org/RSXML/Tour.pdf
#Outstanding guide to XML package : http://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf
## Reading JSON
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
names(jsonData$owner)
jsonData$owner$login
myjson <- toJSON(iris, pretty=TRUE)
cat(myjson)
iris2 <- fromJSON(myjson)
head(iris2)
## Using data.table
library(data.table)
DF <- data.frame(x=rnorm(9), y=rep(c("a","b","c"), each=3), z=rnorm(9))
head(DF, 3)
DT <- data.table(x=rnorm(9), y=rep(c("a","b","c"), each=3), z=rnorm(9))
head(DT, 3)
DT[2, ]
DT[DT$y=="a", ]
DT[c(2, 3)]
DT[, c(2,3)] # not subsetting the columns
{
    x = 1
    y = 2
}
k = {print(10); 5} # 10
print(k) # 5
tables()
DT[, list(mean(x), sum(z))]
DT[, table(y)]
DT[, w:=z^2]
DT
DT2 <- DT
DT[, y:=2]
DT
DT2 # it is changed as well
head(DT, n=3)
DT[, m:={tmp <- (x+z); log2(tmp+5)}]
DT
DT2 # it is changed as well; they point to the same address
DT[, a:=x>0] # plyr like operations
DT
DT[, b:=mean(x+w), by=a] # 'by' performes grouping : calculates mean(x+w) where a = TRUE and places that in all rows where a = TRUE and vice versa for a = FALSE
DT
# Special Numbers
# .N An integer, length 1, containing the number of times a particular group appears
set.seed(123) # Set the seed of R‘s random number generator, which is useful for creating simulations or random objects that can be reproduced.
DT <- data.table(x=sample(letters[1:3], 1E5, TRUE))
DT[, .N, by=x]
# keys
DT <- data.table(x=rep(c("a", "b", "c"), each=100), y=rnorm(300))
setkey(DT, x)
DT['a']
# use keys to do joins
DT1 <- data.table(x=c('a', 'a', 'b', 'dt1'), y=1:4)
DT2 <- data.table(x=c('a', 'b', 'dt2'), z=5:7)
setkey(DT1, x) 
setkey(DT2, x)
merge(DT1, DT2)
# use keys to fast reading
big_df <- data.frame(x=rnorm(1E6), y=rnorm(1E6))
file <- tempfile()
write.table(big_df, file=file, row.names=FALSE, col.names=TRUE, sep="\t", quote=FALSE)
system.time(fread(file))
system.time(read.table(file, header=TRUE, sep="\t")) # so slow
